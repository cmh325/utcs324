{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "In this homework you will learn how to train your first \"deep\" network in tensorflow. In addition we are going to collect some training data, for the next few assignments.\n",
    "\n",
    "Development notes: \n",
    "\n",
    "1) If you are doing your homework in a Jupyter/iPython notebook you may need to 'Restart & Clear Output' after making a change and re-running a cell.  TensorFlow will not allow you to create multiple variables with the same name, which is what you are doing when you run a cell that creates a variable twice.<br/><br/>\n",
    "2) Be careful with your calls to global_variables_initializer(). If you call it after training one network it will re-initialize your variables erasing your training.  In general, double check the outputs of your model after all training and before turning your model in. Ending a session will discard all your variable values.\n",
    "\n",
    "## Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import util\n",
    "\n",
    "I = tf.placeholder(tf.float32, (None,2), name='input')\n",
    "\n",
    "# Give the datapoints a label\n",
    "labels = tf.cast(tf.reduce_sum(I*I, axis=1, keep_dims=True) < 1.0, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: define the compute graph of your linear classifier\n",
    "#x is my training data\n",
    "W = tf.Variable(tf.random_normal([2,1], stddev=0.1),name=\"weights_linear\")\n",
    "b = tf.Variable(tf.zeros(1),name=\"biases_linear\")\n",
    "logits = tf.matmul(I,W) + b\n",
    "linear_output = tf.identity(logits, name='linear_output')\n",
    "\n",
    "# Step 2: use a loss function over your classifier's predictions and the ground truth.\n",
    "loss= tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=linear_output,labels=labels))\n",
    "# # Step 3: create an optimizer\n",
    "optimizer = tf.train.MomentumOptimizer(0.01, 0.9) # 0.1 is the learning rate, 0.9 is the momentum term\n",
    "\n",
    "# # Step 4: use that optimizer on your loss function\n",
    "minimizer = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Non-Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: define the compute graph of your non-linear classifier\n",
    "# Note: use the same input and labels as your linear classifier, python variable 'I' with TF name 'input'\n",
    "#       and python variable labels.\n",
    "#       You will have two branches off the input, your linear and non-linear classifiers\n",
    "\n",
    "layer_size=500\n",
    "W1 = tf.Variable(tf.random_normal([2,layer_size], stddev=0.35),name=\"weights_nonlinear_1\")\n",
    "b1 = tf.Variable(tf.zeros(layer_size),name=\"biases_nonlinear_1\")\n",
    "logit1 = tf.nn.relu(tf.matmul(I,W1)+b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([layer_size,1], stddev=0.35),name=\"weights_nonlinear_2\")\n",
    "b2 = tf.Variable(tf.zeros(1),name=\"biases_nonlinear_2\")\n",
    "logit2 = tf.add(tf.matmul(logit1,W2),b2)\n",
    "\n",
    "nonlinear_output = tf.identity(logit2, name='nonlinear_output')\n",
    "\n",
    "# Step 2: use a loss function over your classifier's predictions and the ground truth.\n",
    "loss_nl= tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=nonlinear_output,labels=labels))\n",
    "# Step 3: create an optimizer\n",
    "optimizer_nl = tf.train.MomentumOptimizer(0.1,0.9)\n",
    "# Step 4: use that optimizer on your loss function\n",
    "minimizer_nl=optimizer_nl.minimize(loss_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Set up training\n",
    "n = 1000\n",
    "train=np.random.random((n,2))\n",
    "\n",
    "# Train linear network\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for iter_train in range(1000):\n",
    "    _,linloss=sess.run([minimizer,loss], feed_dict={I: train})\n",
    "#     print(linloss)\n",
    "    _,nonlinloss=sess.run([minimizer_nl,loss_nl], feed_dict={I: train})\n",
    "#     print(nonlinloss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the current graph\n",
    "util.show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See Learned Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create sample data\n",
    "num_viz_samples = 10000\n",
    "viz_data = np.random.rand(num_viz_samples, 2)\n",
    "\n",
    "labels_outputs = sess.run(labels, feed_dict={I: viz_data})\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.title('Ground Truth')\n",
    "    \n",
    "colors = ['black' if l == 0 else 'orange' for l in labels_outputs]\n",
    "plt.scatter(viz_data[:,0], viz_data[:,1], color=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "### Linear Classifier Outputs ###\n",
    "#################################\n",
    "linear_model_predictions = sess.run(linear_output, feed_dict={I: viz_data})\n",
    "linear_model_predictions = (linear_model_predictions > 0).astype(int)\n",
    "\n",
    "# Plot it\n",
    "colors = ['black' if l == 0 else 'orange' for l in linear_model_predictions]\n",
    "plt.title('Linear Model')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.scatter(viz_data[:,0], viz_data[:,1], color=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "### Non-Linear Classifier Outputs ###\n",
    "#####################################\n",
    "# Run it through the classifiers\n",
    "nonlinear_model_predictions = sess.run(nonlinear_output, feed_dict={I: viz_data})\n",
    "nonlinear_model_predictions = (nonlinear_model_predictions > 0).astype(int)\n",
    "\n",
    "# Plot it\n",
    "colors = ['black' if l == 0 else 'orange' for l in nonlinear_model_predictions]\n",
    "plt.title('Non-linear Model')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.scatter(viz_data[:,0], viz_data[:,1], color=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Save Model\n",
    "Like homework 1 you are turning in your TensorFlow graph.  This time, however, you are saving the trained weights along with the structure.  This is very important because it shows you've trained the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util.save('assignment2.tfg', session=sess)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
