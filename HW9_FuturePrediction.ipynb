{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 9\n",
    "Let's predict the future.\n",
    "\n",
    "## Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import util\n",
    "\n",
    "# Colors to visualize the labeling\n",
    "COLORS = np.array([(0,0,0), (255,0,0), (0,255,0), (255,255,0), (0,0,255), (255,255,255)], dtype=np.uint8)\n",
    "CROP_SIZE = 64\n",
    "N_ACTION = 5\n",
    "\n",
    "offsets = [0, 6, 15, 30, 60, 120]\n",
    "\n",
    "def parser(record):\n",
    "    # Parse the TF record\n",
    "    \n",
    "    feature ={\n",
    "        'height': tf.FixedLenFeature([], tf.int64),\n",
    "        'width': tf.FixedLenFeature([], tf.int64),\n",
    "        'channels': tf.FixedLenFeature([], tf.int64),\n",
    "        'n_future': tf.FixedLenFeature([], tf.int64),\n",
    "        'action': tf.FixedLenFeature([], tf.int64),\n",
    "        'image_raw': tf.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    values = {'position' : np.float32, 'is_dying': np.int64, 'on_ground': np.int64, 'coins': np.int64}\n",
    "    for k,v in enumerate(values):\n",
    "        t = values[v]\n",
    "        for j, o in enumerate(offsets):\n",
    "            feature[v+'_%d'%j] = tf.FixedLenFeature([], t)\n",
    "\n",
    "    parsed = tf.parse_single_example(record, features=feature)\n",
    "     \n",
    "    # Load the data and format it\n",
    "    W = tf.cast(parsed['width'], tf.int32)\n",
    "    H = tf.cast(parsed['height'], tf.int32)\n",
    "    C = tf.cast(parsed['channels'], tf.int32)\n",
    "    A = tf.cast(parsed['action'], tf.int32)\n",
    "    actions = tf.stack([tf.bitwise.bitwise_and(A, (1<<i)) > 0 for i in range(N_ACTION)])\n",
    "    image = tf.reshape(tf.decode_raw(parsed[\"image_raw\"], tf.uint8), [H,W,C])\n",
    "    \n",
    "    current_position = tf.cast(parsed['position_0'], tf.float32)\n",
    "    current_is_dying = tf.cast(parsed['is_dying_0'], tf.bool)\n",
    "    current_coins = tf.cast(parsed['coins_0'], tf.float32)\n",
    "    \n",
    "    future_position = tf.stack([tf.cast(parsed['position_%d'%o], tf.float32) for o in range(1,len(offsets))])\n",
    "    future_is_dying = tf.stack([tf.cast(parsed['is_dying_%d'%o], tf.bool) for o in range(1,len(offsets))])\n",
    "    future_coins = tf.stack([tf.cast(parsed['coins_%d'%o], tf.float32) for o in range(1,len(offsets))])\n",
    "    \n",
    "    ## No data augmentation this time, as it might affect the future\n",
    "    return A, image, actions, current_position, current_is_dying, current_coins, future_position, future_is_dying, future_coins\n",
    "\n",
    "def load_dataset(tfrecord):\n",
    "    # Load the dataset\n",
    "    dataset = tf.contrib.data.TFRecordDataset(tfrecord)\n",
    "\n",
    "    # Parse the tf record entries\n",
    "    dataset = dataset.map(parser, num_threads=8, output_buffer_size=1024)\n",
    "\n",
    "    # Shuffle the data, batch it and run this for multiple epochs\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.batch(32)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Define your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"images:0\", shape=(?, 64, 64, 9), dtype=uint8)\n",
      "Tensor(\"action:0\", shape=(?, 5), dtype=int32)\n",
      "Tensor(\"Cast:0\", shape=(?, 64, 64, 9), dtype=float32)\n",
      "Tensor(\"action:0\", shape=(?, 5), dtype=int32)\n",
      "Tensor(\"current_position:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"current_is_dying:0\", shape=(?,), dtype=bool)\n",
      "Tensor(\"current_coins:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"future_position:0\", shape=(?, 5), dtype=float32)\n",
      "Tensor(\"future_is_dying:0\", shape=(?, 5), dtype=bool)\n",
      "Tensor(\"future_coins:0\", shape=(?, 5), dtype=float32)\n",
      "Total number of variables used  61660\n"
     ]
    }
   ],
   "source": [
    "# Create a new log directory (if you run low on disk space you can either disable this or delete old logs)\n",
    "# run: `tensorboard --logdir log` to see all the nice summaries\n",
    "for n_model in range(1000):\n",
    "    LOG_DIR = 'log/model_%d'%n_model\n",
    "    from os import path\n",
    "    if not path.exists(LOG_DIR):\n",
    "        break\n",
    "\n",
    "# Lets clear the tensorflow graph, so that you don't have to restart the notebook every time you change the network\n",
    "tf.reset_default_graph()\n",
    "\n",
    "TF_COLORS = tf.constant(COLORS)\n",
    "\n",
    "train_data = load_dataset('future_train.tfrecord')\n",
    "valid_data = load_dataset('future_val.tfrecord')\n",
    "\n",
    "# Create an iterator for the datasets\n",
    "# The iterator allows us to quickly switch between training and validataion\n",
    "iterator = tf.contrib.data.Iterator.from_structure(train_data.output_types, ((None,), (None,64,64,9), (None,N_ACTION), (None,), (None,), (None,), (None,len(offsets)-1), (None,len(offsets)-1), (None,len(offsets)-1)))\n",
    "\n",
    "# and fetch the next images from the dataset (every time next_image is evaluated a new image set of 32 images is returned)\n",
    "A, image, action, current_position, current_is_dying, current_coins, future_position, future_is_dying, future_coins = iterator.get_next()\n",
    "\n",
    "# Define operations that switch between train and valid\n",
    "switch_train_op = iterator.make_initializer(train_data)\n",
    "switch_valid_op = iterator.make_initializer(valid_data)\n",
    "\n",
    "# Convert the input and label\n",
    "image = tf.identity(image, name='images')\n",
    "print(image)\n",
    "image = tf.cast(image, tf.float32)\n",
    "action = tf.identity(tf.cast(action, tf.int32), name='action')\n",
    "\n",
    "current_position = tf.identity(current_position, name='current_position')\n",
    "current_is_dying = tf.identity(current_is_dying, name='current_is_dying')\n",
    "current_coins = tf.identity(current_coins, name='current_coins')\n",
    "\n",
    "future_position = tf.identity(future_position, name='future_position')\n",
    "future_is_dying = tf.identity(future_is_dying, name='future_is_dying')\n",
    "future_coins = tf.identity(future_coins, name='future_coins')\n",
    "\n",
    "print(action)\n",
    "print(image)\n",
    "print(action)\n",
    "print(current_position)\n",
    "print(current_is_dying)\n",
    "print(current_coins)\n",
    "print(future_position)\n",
    "print(future_is_dying)\n",
    "print(future_coins)\n",
    "\n",
    "# Whiten the image\n",
    "white_image = (image - 100.) / 72.\n",
    "\n",
    "# TODO: Define your convnet and loss here\n",
    "# In preparation for the next homework you might want to make this network small and efficient.\n",
    "\n",
    "# Build the network out of a few convolutional layers\n",
    "h = white_image\n",
    "for i, n in enumerate([10,20,30,40,50,60]):\n",
    "    h = tf.contrib.layers.conv2d(h, 20, (3,3), stride=2, scope=\"conv%d\"%i)\n",
    "h = tf.contrib.layers.flatten(h)\n",
    "\n",
    "# Hook up a fully connected layer to predict the action\n",
    "action_logit = tf.contrib.layers.fully_connected(h, N_ACTION, activation_fn=None)\n",
    "\n",
    "# Combine the action and the output of the conv layer\n",
    "outer_product = tf.contrib.layers.flatten( tf.cast(action[:,None,:], tf.float32) * h[:,:,None] )\n",
    "h = tf.contrib.layers.fully_connected(outer_product, 200)\n",
    "h = tf.contrib.layers.fully_connected(h, 100)\n",
    "future_position_logit = tf.contrib.layers.fully_connected(h, len(offsets)-1, activation_fn=None) + current_position[:,None]\n",
    "future_is_dying_logit = tf.contrib.layers.fully_connected(h, len(offsets)-1, activation_fn=None) + tf.cast(current_is_dying[:,None], tf.float32)-0.5\n",
    "future_coins_logit = tf.contrib.layers.fully_connected(h, len(offsets)-1, activation_fn=None) + current_coins[:,None]\n",
    "\n",
    "# Use a cross entropy for the action and is_dying, L2 for position and coin.\n",
    "action_loss = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(action, tf.float32), logits=action_logit) )\n",
    "is_dying_loss = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(future_is_dying, tf.float32), logits=future_is_dying_logit) )\n",
    "position_loss = tf.reduce_mean( tf.nn.l2_loss(future_position_logit-future_position) )\n",
    "coins_loss = tf.reduce_mean( tf.nn.l2_loss(future_coins_logit-future_coins) )\n",
    "loss = 0.05*coins_loss + position_loss + is_dying_loss + action_loss\n",
    "\n",
    "# a binary vector of size 5 for each image in the batch (DO NOT USE action TO PREDICT THIS!)\n",
    "pred_action = tf.identity(action_logit > 0.5, name='predicted_action')\n",
    "\n",
    "# vectors of size (5) for each image in the batch (USE action AND current_position, current_is_dying, current_coins TO PREDICT THIS)\n",
    "# Hint for some variables you might want to make them relative to current_..., for others not\n",
    "pred_is_dying = tf.identity(future_is_dying_logit > 0.5, name='predicted_is_dying')\n",
    "pred_position = tf.identity(future_position_logit, name='predicted_position')\n",
    "pred_coins = tf.identity(future_coins_logit, name='predicted_coins')\n",
    "\n",
    "# Accuracies\n",
    "action_acc = tf.reduce_mean(tf.cast(tf.equal(tf.cast(pred_action, tf.float32), tf.cast(action, tf.float32)), tf.float32))\n",
    "dying_acc = tf.reduce_mean(tf.cast(tf.equal(tf.cast(pred_is_dying, tf.float32), tf.cast(future_is_dying, tf.float32)), tf.float32))\n",
    "\n",
    "# Let's weight the regularization loss down, otherwise it will hurt the model performance\n",
    "# You can tune this weight if you wish\n",
    "regularization_loss = tf.losses.get_regularization_loss()\n",
    "total_loss = loss + 1e-6 * regularization_loss\n",
    "\n",
    "# Adam will likely converge much faster than SGD for this assignment.\n",
    "optimizer = tf.train.AdamOptimizer(0.001, 0.9, 0.999)\n",
    "\n",
    "# use that optimizer on your loss function (control_dependencies makes sure any \n",
    "# batch_norm parameters are properly updated)\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "    opt = optimizer.minimize(total_loss)\n",
    "\n",
    "# Let's define some summaries for tensorboard\n",
    "tf.summary.image('image1', image[:,:,:,:3], max_outputs=3)\n",
    "tf.summary.image('image2', image[:,:,:,3:6], max_outputs=3)\n",
    "tf.summary.image('image3', image[:,:,:,6:9], max_outputs=3)\n",
    "tf.summary.scalar('action_loss', tf.placeholder(tf.float32, name='action_loss'))\n",
    "tf.summary.scalar('is_dying_loss', tf.placeholder(tf.float32, name='is_dying_loss'))\n",
    "tf.summary.scalar('position_loss', tf.placeholder(tf.float32, name='position_loss'))\n",
    "tf.summary.scalar('coins_loss', tf.placeholder(tf.float32, name='coins_loss'))\n",
    "tf.summary.scalar('loss', tf.placeholder(tf.float32, name='loss'))\n",
    "tf.summary.scalar('val_loss', tf.placeholder(tf.float32, name='val_loss'))\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR, tf.get_default_graph())\n",
    "\n",
    "# Let's compute the model size\n",
    "print( \"Total number of variables used \", np.sum([v.get_shape().num_elements() for v in tf.trainable_variables()]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Training\n",
    "\n",
    "Training might take up to 20 min depending on your architecture (and if you have a GPU or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0] Loss: 0.796  \t  val loss A.: 0.895\n",
      "[  1] Loss: 0.522  \t  val loss A.: 0.422\n",
      "[  2] Loss: 0.454  \t  val loss A.: 0.339\n",
      "[  3] Loss: 0.408  \t  val loss A.: 0.355\n",
      "[  4] Loss: 0.399  \t  val loss A.: 0.457\n",
      "[  5] Loss: 0.393  \t  val loss A.: 1.119\n",
      "[  6] Loss: 0.393  \t  val loss A.: 0.323\n",
      "[  7] Loss: 0.380  \t  val loss A.: 0.350\n",
      "[  8] Loss: 0.384  \t  val loss A.: 0.367\n",
      "[  9] Loss: 0.371  \t  val loss A.: 0.417\n"
     ]
    }
   ],
   "source": [
    "# Start a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Set up training\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Run the training for some iterations\n",
    "for it in range(10):\n",
    "    sess.run(switch_train_op)\n",
    "\n",
    "    loss_vals = []\n",
    "    # Run 10 training iterations and 1 validation iteration\n",
    "    for i in range(100):\n",
    "        loss_val = sess.run([loss,action_loss,is_dying_loss,position_loss,coins_loss,opt])[:-1]\n",
    "        loss_vals.append(loss_val)\n",
    "    # Compute the summary\n",
    "    mean_loss = np.mean(np.array(loss_vals), axis=0)\n",
    "    summary = {n+':0':mean_loss[i] for i, n in enumerate(['loss','action_loss','is_dying_loss','position_loss','coins_loss'])}\n",
    "\n",
    "    # Compute the validation loss\n",
    "    sess.run(switch_valid_op)\n",
    "    loss_val = sess.run(loss)\n",
    "    summary['val_loss:0'] = loss_val\n",
    "    \n",
    "    summary_writer.add_summary( sess.run(merged_summary, summary), it )\n",
    "\n",
    "    # Let's update tensorboard\n",
    "    print('[%3d] Loss: %0.3f  \\t  val loss A.: %0.3f'%(it, mean_loss[0], loss_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Evaluation\n",
    "### Compute the validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "Action accuracy: 0.863719\n",
      "Is-Dying accuracy: 0.998724\n",
      "Position L2: 0.0012136\n",
      "Coin L2: 0.000202293\n"
     ]
    }
   ],
   "source": [
    "action_p = tf.placeholder(tf.int32, shape=(None))\n",
    "dying_p = tf.placeholder(tf.bool, shape=(None))\n",
    "pos_p = tf.placeholder(tf.float32, shape=(None))\n",
    "coins_p = tf.placeholder(tf.float32, shape=(None))\n",
    "\n",
    "#####################\n",
    "action_accs = []\n",
    "dying_accs = []\n",
    "pos_losses = []\n",
    "coin_losses = []\n",
    "index = 0\n",
    "for it in tf.python_io.tf_record_iterator('future_val.tfrecord'):\n",
    "    index += 1\n",
    "    if index % 10 == 0:\n",
    "        print(index)\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(it)\n",
    "    \n",
    "    # Get ground truth inputs\n",
    "    I = np.expand_dims(np.frombuffer(example.features.feature['image_raw'].bytes_list.value[0], dtype=np.uint8).reshape(64, 64, 9), axis=0)\n",
    "    A = example.features.feature['action'].int64_list.value[0]\n",
    "    action = tf.stack([tf.bitwise.bitwise_and(action_p, (1<<i)) > 0 for i in range(N_ACTION)])\n",
    "    current_position = [example.features.feature['position_0'].float_list.value[0]]\n",
    "    current_is_dying = [example.features.feature['is_dying_0'].int64_list.value[0]]\n",
    "    current_coins = [example.features.feature['coins_0'].int64_list.value[0]]\n",
    "    \n",
    "    # Get ground truth labels\n",
    "    val_future_pos = np.expand_dims(np.array([example.features.feature['position_%d'%o].float_list.value[0] for o in range(1,len(offsets))]), axis=-1)\n",
    "    val_future_dying = np.expand_dims(np.array([example.features.feature['is_dying_%d'%o].int64_list.value[0] for o in range(1,len(offsets))]), axis=-1)\n",
    "    val_future_coins = np.expand_dims(np.array([example.features.feature['coins_%d'%o].int64_list.value[0] for o in range(1,len(offsets))]), axis=-1)\n",
    "    \n",
    "    future_position = tf.stack(tf.cast(pos_p, tf.float32))\n",
    "    future_is_dying = tf.stack(tf.cast(dying_p, tf.float32))\n",
    "    future_coins = tf.stack(tf.cast(coins_p, tf.float32))\n",
    "    \n",
    "    action, future_position, future_is_dying, future_coins = sess.run([action, future_position, future_is_dying, future_coins], {action_p: A, pos_p: val_future_pos, dying_p: val_future_dying, coins_p: val_future_coins})\n",
    "    action = np.expand_dims(np.array(action), axis=0)\n",
    "    \n",
    "    # Make predictions\n",
    "    action_pred, pos_pred, dying_pred, coins_pred = sess.run([tf.cast(pred_action, tf.float32), future_position_logit, tf.cast(pred_is_dying, tf.float32), future_coins_logit], {'images:0': I, 'action:0': action, 'current_position:0': current_position, 'current_is_dying:0': current_is_dying, 'current_coins:0': current_coins})\n",
    "    action_pred = action_pred[0]\n",
    "    pos_pred = pos_pred[0]\n",
    "    dying_pred = dying_pred[0]\n",
    "    coins_pred = coins_pred[0]\n",
    "    \n",
    "    # Score predictions\n",
    "    val_action_acc = np.mean((action_pred == action).astype('float32'))\n",
    "    val_dying_acc = np.mean((dying_pred == future_is_dying).astype('float32'))\n",
    "    val_pos_acc = np.mean((pos_pred - future_position) ** 2)\n",
    "    val_coin_acc = np.mean((coins_pred - future_coins) ** 2)\n",
    "    \n",
    "    action_accs.append(val_action_acc)\n",
    "    dying_accs.append(val_dying_acc)\n",
    "    pos_losses.append(val_pos_acc)\n",
    "    coin_losses.append(val_coin_acc)\n",
    "    \n",
    "print('Action accuracy: ' + str(np.mean(action_accs)))\n",
    "print('Is-Dying accuracy: ' + str(np.mean(dying_accs)))\n",
    "print('Position L2: ' + str(np.mean(pos_losses)))\n",
    "print('Coin L2: ' + str(np.mean(coin_losses)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Save Model\n",
    "Please note that we also want you to turn in your ipynb for this assignment.  Zip up the ipynb along with the tfg for your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.save('assignment9.tfg', session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
